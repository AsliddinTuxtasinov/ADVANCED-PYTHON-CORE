# ğŸŒ€ Advanced Async Context Managers
> async with protokoli Â· Connection Pooling Â· Redis Â· DB Sessions

## ğŸ”¥ KIRISH

Async context managers â€” bu async resurslar (DB connection, Redis connection, lock, file, network stream) bilan ishlashning eng toâ€˜gâ€˜ri va xavfsiz usuli.

Ular quyidagilarni avtomatik boshqaradi:

* Connection ochish / yopish
* Transaction boshlash / commit / rollback
* Lock acquisition / release
* Resource leasing / freeing
* Pool ichidan connection olish / qaytarish

Backend arxitekturasida bu perfomance + correctness uchun juda muhim.

## ğŸ§© async with PROTOKOLI

Async context manager quyidagilarga ega boâ€˜lishi shart:

```python
class A:
    async def __aenter__(self):
        ...
    async def __aexit__(self, exc_type, exc, tb):
        ...
```

**Diagram:**

```python
async with manager:
    body
```

1. `await manager.__aenter__()`
2. `body` ichidagi kod bajariladi
3. `await manager.__aexit__(...)`

Agar exception boâ€˜lsa â€” `__aexit__` exceptionni boshqaradi.

## ğŸ”§ ASYNC CONTEXT MANAGER INTERNALS

```python
async with X() as conn:
    ...
```

Event Loop quyidagi tartibda ishlaydi:

`call __aenter__()` â†’ `allocate resource` â†’ `return object`
`execute body`
`call __aexit__()` â†’ `release resource` â†’ `commit/rollback`

### __aexit__ argumentlari:

* `exc_type` â†’ Exception class
* `exc` â†’ Exception instance
* `tb` â†’ traceback

Agar `__aexit__` â†’ `True` qaytarsa exception suppression qilinadi.

## ğŸ›  CUSTOM ASYNC CONTEXT MANAGER YOZISH

### Minimal misol:

```python
class AsyncTimer:
    async def __aenter__(self):
        self.start = time.monotonic()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        self.duration = time.monotonic() - self.start
        print(f"Finished in {self.duration:.3f}s")
```

**Foydalanish:**

```python
async with AsyncTimer():
    await asyncio.sleep(2)
```

### ğŸ”¥ More Advanced â€” Connection leasing simulation

```python
class FakeConnection:
    async def open(self):
        print("Opening connection...")
    async def close(self):
        print("Closing connection...")

class ConnectionCtx:
    def __init__(self, pool):
        self.pool = pool

    async def __aenter__(self):
        self.conn = await self.pool.acquire()
        return self.conn

    async def __aexit__(self, exc_type, exc, tb):
        await self.pool.release(self.conn)
```

Async context manager asosiy vazifasi â€” pooldan connection olish va qaytarish.

## ğŸ— CONNECTION POOLING â€” ARXITEKTURA

Pooling â€” resurslarni qayta ishlatish tamoyili.

**Diagram:**

```text
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Connection   â”‚  â† 10â€“100 db connections
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚ acquired / released
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    Connection    â”‚
 â”‚       Pool       â”‚
 â”‚  (async safe)    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
   async with get_session()
```

**Nima uchun zarur?**

* DB connection ochish â†’ juda qimmat (TCP handshake, auth, TLS)
* Har request uchun connection ochish â†’ high latency
* Pool performanceâ€™ni 10â€“20 barobar oshiradi

## ğŸ› ASYNC DB SESSION (POSTGRESQL) â€” ADVANCED FLOW

SQLAlchemy / asyncpg / databases libraryâ€™dagi jarayonlar bir xil tamoyilga ega.

### Session lifecycle (advanced):
`pool.acquire()` â†’ `connection` â†’ `begin transaction`
â†“
`session (unit of work)`
â†“
`commit / rollback`
â†“
`pool.release()`

### Misol (SQLAlchemy + AsyncSession):

```python
from sqlalchemy.ext.asyncio import async_sessionmaker

async_session = async_sessionmaker(engine, expire_on_commit=False)

async def get_db():
    async with async_session() as session:
        try:
            yield session
        except:
            await session.rollback()
            raise
        finally:
            await session.close()
```

Bu yerda `async with` â†’ `aenter()` ichida db connection olinadi.

## âš¡ REDIS ASYNC CONNECTION POOLING

`aioredis` / `redis.async` libraryâ€™da pool default.

### Redis pool yaratish:

```python
from redis.asyncio import ConnectionPool, Redis

pool = ConnectionPool.from_url("redis://localhost:6379", max_connections=20)
redis = Redis(connection_pool=pool)
```

**Async context manager sifatida:**

```python
async with redis.client() as conn:
    await conn.set("key", "value")
```

**Ichkarida:**

* `pool` â†’ connection qaytaradi
* `aenter` â†’ leasing
* `aexit` â†’ releasing

## ğŸŒ FASTAPIâ€™DA ASYNC DB SESSION DEPENDENCY

```python
from fastapi import Depends

async def get_session() -> AsyncSession:
    async with async_session() as session:
        yield session

@app.get("/users")
async def get_users(db: AsyncSession = Depends(get_session)):
    return await db.execute(...)
```

**FastAPI dependency injection:**

* bir request = bir session
* session `async with` orqali toâ€˜gâ€˜ri boshqariladi
* exception boâ€˜lsa â†’ rollback
* responsedan keyin â†’ release

## ğŸ› POOLING ADVANCED MUAMMOLARI

### 1ï¸âƒ£ Connection leak

Session yopilmasa pool toâ€˜ladi â†’ API down boâ€˜ladi.

**Shuning uchun:**
* har doim `async with` ishlating

### 2ï¸âƒ£ Pool starvation

Barcha connectionlar band â†’ soâ€˜rovlar kutib qoladi.

**Yechimlar:**
* pool size oshirish
* read replica qoâ€˜shish
* long-running querylarni optimallashtirish

### 3ï¸âƒ£ Zombie connection

Network breakdown â†’ connection alive tuyuladi lekin ishlamaydi.

**Yechim:**
* pool.recycle
* health-check pingi

### 4ï¸âƒ£ Transaction never closed

`await session.begin()` â†’ `commit()` unutilgan boâ€˜lsa:

* deadlock
* locks oshadi
* performance pasayadi

## ğŸ§ª ADVANCED CUSTOM CONTEXT MANAGER â€” TRANSACTION MANAGER

Bu profi-level pattern:

```python
class Transaction:
    def __init__(self, session):
        self.session = session

    async def __aenter__(self):
        self.tx = await self.session.begin()
        return self.session
    
    async def __aexit__(self, exc_type, exc, tb):
        if exc_type:
            await self.tx.rollback()
        else:
            await self.tx.commit()
```

**Foydalanish:**

```python
async with Transaction(session) as db:
    await db.execute(...)
```

## ğŸ“˜ XULOSA

Siz endi quyidagi advanced mavzularni toâ€˜liq oâ€˜rgandingiz:

* âœ“ `async with` protokoli (internal state machine)
* âœ“ Custom async context managerlar
* âœ“ Connection pooling arxitekturasi (DB/Redis)
* âœ“ AsyncSession lifecycle (acquire â†’ begin â†’ commit â†’ release)
* âœ“ FastAPI dependency injection bilan integratsiya
* âœ“ Poolingdagi advanced muammolar

Bu bilimlar high-performance backend, distributed systems, microservices, FastAPI, SQLAlchemy, asyncpg, Redis, va network IO kod yozishda majburiy.

---

# ğŸ§© ADVANCED ASYNC DATABASE & REDIS MECHANICS
> Isolation Levels Â· Pool Starvation Monitoring Â· Redis Pipelining Â· Async File Context Managers Â· High-Performance DB Middleware

## 1ï¸âƒ£ ASYNC TRANSACTION ISOLATION LEVELS
> PostgreSQL / SQLAlchemy / asyncpg â€” Arxitektura & real misollar

Transaction isolation â€” transactionlar bir-biriga qanchalik taâ€™sir qilishini belgilaydi.

**PostgreSQLâ€™dagi 4 daraja:**

| Isolation level | Dirty Read | Non-Repeatable Read | Phantom Read |
| :--- | :--- | :--- | :--- |
| **READ UNCOMMITTED** | possible | possible | possible |
| **READ COMMITTED** (default) | âŒ | possible | possible |
| **REPEATABLE READ** | âŒ | âŒ | possible |
| **SERIALIZABLE** | âŒ | âŒ | âŒ (strict) |

### â–¶ READ COMMITTED (default)

Har query transaction ichida ishlatilmaydi â€” har query fresh snapshot oladi.
FastAPI uchun eng xavfsiz default setting.

```python
async with async_session.begin() as s:
    await s.execute(text("SET TRANSACTION ISOLATION LEVEL READ COMMITTED"))
```

### â–¶ REPEATABLE READ

Bir transaction â†’ bitta snapshot.
Long-running querylar phantom readlarga olib kelishi mumkin.

```python
await s.execute(text("SET TRANSACTION ISOLATION LEVEL REPEATABLE READ"))
```

### â–¶ SERIALIZABLE (most strict)

PostgreSQL konflikt boâ€˜lsa transactionni abort qiladi.
High-concurrency APIâ€™larda abort â†’ retry loop talab qiladi.

```python
async with Transaction(session, isolation="SERIALIZABLE"):
    ...
```

**Custom manager:**

```python
class Transaction:
    def __init__(self, session, isolation="READ COMMITTED"):
        self.session = session
        self.isolation = isolation

    async def __aenter__(self):
        await self.session.execute(
            text(f"SET TRANSACTION ISOLATION LEVEL {self.isolation}")
        )
        return self.session

    async def __aexit__(self, exc_type, exc, tb):
        if exc_type:
            await self.session.rollback()
        else:
            await self.session.commit()
```

**ğŸ§ª SERIALIZABLE uchun retry pattern**

```python
for _ in range(5):
    try:
        async with Transaction(session, isolation="SERIALIZABLE") as tx:
            await tx.execute(...)    
        break
    except SerializationFailure:
        await asyncio.sleep(0.01)
```

Production bank tizimlari shuni ishlatadi.

## 2ï¸âƒ£ POOL STARVATION MONITORING
> Pool band boâ€˜lib qolishi (dead pool) â€” advanced diagnostics

Pool starvation â†’ application hanging.

**Sabablari:**
* Session yopilmay qolgan (connection leak)
* Pool sizaga yetmaydi
* Long-running querylar
* Transactionlar hech tugamaydi

**Monitoring pattern:**

### â–¶ SQLAlchemy: connection borrow time log

```python
from time import monotonic

class LogPool:
    async def __aenter__(self):
        self.start = monotonic()
        self.conn = await engine.connect()
        return self.conn

    async def __aexit__(self, exc_type, exc, tb):
        duration = monotonic() - self.start
        if duration > 0.5:
            print(f"âš ï¸ Connection borrowed too long: {duration:.2f}s")
        await self.conn.close()
```

### â–¶ Pool overflow detection

```python
if pool.overflow() > 20:
    print("âš ï¸ Pool overflow detected!")
```

### â–¶ Periodik monitoring task

```python
async def pool_metrics():
    while True:
        print("Checked out:", engine.pool.checkedout())
        print("Available:", engine.pool.size() - engine.pool.checkedout())
        await asyncio.sleep(2)
```

FastAPI startup eventiga qoâ€˜shiladi.

## 3ï¸âƒ£ REDIS PIPELINING + POOLING
> High-performance Redis operations (10x faster)

Pipelining â†’ bir nechta Redis komandalarini bitta network paketda yuborish.

### â–¶ aioredis pipelining

```python
async with redis.pipeline(transaction=False) as pipe:
    pipe.set("a", 1)
    pipe.set("b", 2)
    pipe.incr("counter")
    results = await pipe.execute()
```

4 network roundtrip â†’ 1 roundtrip

### â–¶ Pipelining + connection pool

**ConnectionPool:**

```python
from redis.asyncio import Redis, ConnectionPool

pool = ConnectionPool.from_url("redis://localhost:6379", max_connections=50)
redis = Redis(connection_pool=pool)
```

**Pipelining that reuses pooled connection:**

```python
async with redis.pipeline() as p:
    for i in range(1000):
        p.incr(f"u:{i}:clicks")
    await p.execute()
```

### â–¶ Redis pub/sub with pooled connections

```python
async with redis.pubsub() as ps:
    await ps.subscribe("events")
    async for msg in ps.listen():
        print(msg)
```

## 4ï¸âƒ£ ASYNC FILE CONTEXT MANAGERS
> aiofiles, streaming, chunked reading â€” large files uchun

### â–¶ Basic async file reading

```python
import aiofiles

async with aiofiles.open("data.txt", "r") as f:
    async for line in f:
        print(line)
```

### â–¶ Chunk-based async copy

Production S3 â†’ disk â†’ S3 pipeline uslubi:

```python
async def async_copy(src, dst):
    async with aiofiles.open(src, "rb") as fsrc:
        async with aiofiles.open(dst, "wb") as fdst:
            while True:
                chunk = await fsrc.read(1024 * 1024)
                if not chunk:
                    break
                await fdst.write(chunk)
```

### â–¶ Async temporary file manager

```python
class TempFile:
    def __init__(self, path):
        self.path = path

    async def __aenter__(self):
        self.f = await aiofiles.open(self.path, "w+")
        return self.f

    async def __aexit__(self, exc_type, exc, tb):
        await self.f.close()
        os.remove(self.path)
```

## 5ï¸âƒ£ HIGH-PERFORMANCE DB MIDDLEWARE
> FastAPI + async SQLAlchemy â€” request-level session management

**Pattern:**
`request` â†’ `open session` â†’ `begin transaction` â†’ `handler` â†’ `commit or rollback` â†’ `release connection` â†’ `response`

### â–¶ Full middleware code (production-safe)

```python
from starlette.middleware.base import BaseHTTPMiddleware

class DBSessionMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        async with async_session() as session:
            request.state.db = session

            try:
                response = await call_next(request)
                await session.commit()
            except Exception:
                await session.rollback()
                raise
            finally:
                await session.close()

        return response
```

**Use in FastAPI:**

```python
app.add_middleware(DBSessionMiddleware)
```

### â–¶ Katta load ostida performance optimallashtirish

* `sessionmaker expire_on_commit=False`
* Pool sizing:
  * min: CPU * 2
  * max: CPU * 5
* Read-only queries uchun read replica pool
* Heavy queries uchun `to_thread` (blocking operations)
* Query cache (Redis, in-memory LRU)

### â–¶ Middleware monitoring

**Add timing:**

```python
start = time.monotonic()
response = await call_next(request)
duration = (time.monotonic() - start)

if duration > 0.3:
    print("âš ï¸ Slow DB request:", request.url)
```

## ğŸ“˜ XULOSA (super-qisqa)

Siz endi fully advanced darajada oâ€˜rgandingiz:

* âœ“ Transaction isolation levels + retry pattern
* âœ“ Pool starvation monitoring + metrics
* âœ“ Redis pipelining + connection pooling
* âœ“ Async file context managers (large file pipeline)
* âœ“ High-performance async DB middleware (production pattern)

Bu mavzular senior Python backend, high-load FastAPI, distributed systems, async microservicesda ishlatiladigan professional texnikalar.
